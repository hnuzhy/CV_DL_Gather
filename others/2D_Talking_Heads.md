# 2D Talking Heads
also named ***Speech-driven 3D Facial Animation*** or ***Audio2Face***

# Materials


# Papers

* **(TOG2017)** Audio-Driven Facial Animation by Joint End-to-End Learning of Pose and Emotion [[paper link](https://dl.acm.org/doi/abs/10.1145/3072959.3073658)][[PPT link](https://pdfs.semanticscholar.org/95b8/03d07c37e8349bd7b1318367d8237c76cbc0.pdf)]

* **(TOG2017)** A Deep Learning Approach for Generalized Speech Animation [[paper link](https://dl.acm.org/doi/abs/10.1145/3072959.3073699)][[pdf link](https://ueaeprints.uea.ac.uk/id/eprint/64948/1/Accepted_manuscript.pdf)]

* **VOCA(CVPR2019)** Capture, Learning, and Synthesis of 3D Speaking Styles [[paper link](https://openaccess.thecvf.com/content_CVPR_2019/html/Cudeiro_Capture_Learning_and_Synthesis_of_3D_Speaking_Styles_CVPR_2019_paper.html)][[project link](https://voca.is.tue.mpg.de/)][[code|official](https://github.com/TimoBolkart/voca)][`MPII Lab`]

* **MeshTalk(ICCV2021)** MeshTalk: 3D Face Animation From Speech Using Cross-Modality Disentanglement
 [[paper link](https://openaccess.thecvf.com/content/ICCV2021/html/Richard_MeshTalk_3D_Face_Animation_From_Speech_Using_Cross-Modality_Disentanglement_ICCV_2021_paper.html)][[code|official PyTorch](https://github.com/facebookresearch/meshtalk)][`Facebook`]

* **FaceFormer(CVPR2022)** FaceFormer: Speech-Driven 3D Facial Animation With Transformers [[paper link](https://openaccess.thecvf.com/content/CVPR2022/html/Fan_FaceFormer_Speech-Driven_3D_Facial_Animation_With_Transformers_CVPR_2022_paper.html)][[project link](https://evelynfan.github.io/audio2face/)][[code|official PyTorch](https://github.com/EvelynFan/FaceFormer)]

* **GeneFace(ICLR2023)** GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis [[paper link](https://arxiv.org/abs/2301.13430)][[project link](https://geneface.github.io/)][[code|official PyTorch](https://github.com/yerfor/GeneFace)][`ZJU`]

* **CodeTalker(arxiv2023)** CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior [[paper link](https://arxiv.org/abs/2301.02379)][[project link](https://doubiiu.github.io/projects/codetalker/)][`Tencent`]

* **SadTalker(CVPR2023)** SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation [[paper link](https://arxiv.org/abs/2211.12194)][[project link](https://sadtalker.github.io/)][[code|official](https://github.com/Winfredy/SadTalker)][`Xi'an Jiaotong University`, `Tencent AI Lab`, `Ant Group`]

* **DisCoHead(ICASSP2023)** DisCoHead: Audio-and-Video-Driven Talking Head Generation by Disentangled Control of Head Pose and Facial Expressions [[paper link](https://arxiv.org/abs/2303.07697)][[project link](https://deepbrainai-research.github.io/discohead/)]
