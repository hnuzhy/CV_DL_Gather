# Human Motion Imitation
*also closely related to `Humanoid Reaction Synthesis`, `Physically Simulated Humanoids`, `Physics-based Motion Imitation` and `Humanoid Robot Control`*

## ‚ñ∂Materials


***

## ‚ñ∂Datasets


***

## ‚ñ∂Papers

* **PACER(CVPR2023)(arxiv2023.04)** Trace and Pace: Controllable Pedestrian Animation via Guided Trajectory Diffusion [[paper link](http://openaccess.thecvf.com/content/CVPR2023/html/Rempe_Trace_and_Pace_Controllable_Pedestrian_Animation_via_Guided_Trajectory_Diffusion_CVPR_2023_paper.html)][[arxiv link](https://arxiv.org/abs/2304.01893)][[project link](https://research.nvidia.com/labs/toronto-ai/trace-pace/)][[code|official](https://github.com/nv-tlabs/pacer)][`NVIDIA + Stanford`; the first authors are [`Davis Rempe`](https://davrempe.github.io/) and [`Zhengyi Luo (ÁΩóÊ≠£ÂÆú)`](https://www.zhengyiluo.com/)]

* **PHC(PerpetualHumanoidControl)(ICCV2023)(arxiv2023.05)** Perpetual Humanoid Control for Real-time Simulated Avatars [[paper link](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_Perpetual_Humanoid_Control_for_Real-time_Simulated_Avatars_ICCV_2023_paper.html)][[arxiv link](https://arxiv.org/abs/2305.06456)][[project link](https://www.zhengyiluo.com/PHC-Site/)][[code|official](https://github.com/ZhengyiLuo/PerpetualHumanoidControl)][`Meta` and `CMU`; the first author [`Zhengyi Luo (ÁΩóÊ≠£ÂÆú)`](https://www.zhengyiluo.com/)]

* **MoConVQ(arxiv2023.10)** MoConVQ: Unified Physics-Based Motion Control via Scalable Discrete Representations [[arxiv link](https://arxiv.org/abs/2310.10198)][[project link](https://moconvq.github.io/)][`PKU`]

* **PULSE(ICLR2024 spotlight)(arxiv2023.10)** Universal Humanoid Motion Representations for Physics-Based Control [[openreview link](https://openreview.net/forum?id=OrOd8PxOO2)][[arxiv link](https://arxiv.org/abs/2310.04582)][[project link](https://www.zhengyiluo.com/PULSE-Site/)][[code|official](https://github.com/ZhengyiLuo/PULSE)][`Meta` and `CMU`; the first author [`Zhengyi Luo (ÁΩóÊ≠£ÂÆú)`](https://www.zhengyiluo.com/)]

* ‚ù§**FLD(ICLR2024 spotlight)(arxiv2024.02)** FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning [[openreview link](https://openreview.net/forum?id=xsd2llWYSA)][[arxiv link](https://arxiv.org/abs/2402.13820)][[project link](https://sites.google.com/view/iclr2024-fld/home)][[weixin blog](https://mp.weixin.qq.com/s/0FR9Tu-91GfFkUU-4YR0dA)][[code|official](https://github.com/mit-biomimetics/fld)][`MIT`, `RL-based` Policy][It demonstrates its representation and generation capability with a `robotic motion tracking` task on [`MIT Humanoid`](https://spectrum.ieee.org/mit-dynamic-acrobatic-humanoid-robot) using [`NVIDIA Isaac Gym`](https://developer.nvidia.com/isaac-gym).]

* **ExBody(RSS2024)(arxiv2024.02)** Expressive Whole-Body Control for Humanoid Robots [[arxiv link](https://arxiv.org/abs/2402.16796)][[project link](https://expressive-humanoid.github.io/)][`UC San Diego + HKUST`; related to [`Xiaolong Wang`](https://xiaolonw.github.io/) group; using the `Unitree H1 humanoid`]

* **FlowMDM(CVPR2024)(arxiv2024.02)** Seamless Human Motion Composition with Blended Positional Encodings [[arxiv link](https://arxiv.org/abs/2402.15509)][[project link](https://barquerogerman.github.io/FlowMDM/)][[code|official](https://github.com/BarqueroGerman/FlowMDM)][`University of Barcelona, Spain`]

* **SimXR(CVPR2024)(arxiv2024.03)** Real-Time Simulated Avatar from Head-Mounted Sensors [[arxiv link](https://arxiv.org/abs/2403.06862)][[project link](https://www.zhengyiluo.com/SimXR-Site/)][`Meta` and `CMU`; the first author [`Zhengyi Luo (ÁΩóÊ≠£ÂÆú)`](https://www.zhengyiluo.com/)]

* **PACER+(CVPR2024)(arxiv2024.04)** PACER+: On-Demand Pedestrian Animation Controller in Driving Scenarios [[arxiv link](https://arxiv.org/abs/2404.19722)][[project link](https://wangjingbo1219.github.io/papers/CVPR2024_PACER_PLUS/PACERPLUSPage.html)][[code|official](https://github.com/IDC-Flash/PacerPlus)][`Shanghai AI LAB + CMU + Nvidia + CUHK`; the first author [`Jingbo Wang`](http://wangjingbo.top/) and [`Zhengyi Luo (ÁΩóÊ≠£ÂÆú)`](https://www.zhengyiluo.com/)]

* üëç**H2O(arxiv2024.03)** Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation [[arxiv link](https://arxiv.org/abs/2403.04436)][[project link](https://human2humanoid.com/)][`CMU`, using the `Unitree H1 humanoid`; the first author [`Tairan He ‰ΩïÊ≥∞ÁÑ∂`](https://tairanhe.com/) and [`Zhengyi Luo (ÁΩóÊ≠£ÂÆú)`](https://www.zhengyiluo.com/)]

* **LDP(arxiv2024.03)** Human Motion Prediction under Unexpected Perturbation [[arxiv link](https://arxiv.org/abs/2403.15891)][`University of Leeds, United Kingdom + INRIA, France`]

* **PhysReaction(arxiv2024.04)** PhysReaction: Physically Plausible Real-Time Humanoid Reaction Synthesis via Forward Dynamics Guided 4D Imitation [[arxiv link](https://arxiv.org/abs/2404.01081)][[project link](https://yunzeliu.github.io/PhysReaction/)][`THU + Shanghai AI Lab + Shanghai Qi Zhi`]

* **LMM(arxiv2024.04)** Large Motion Model for Unified Multi-Modal Motion Generation [[arxiv link](https://arxiv.org/abs/2404.01284)][[project link](https://mingyuan-zhang.github.io/projects/LMM.html)][[code|official](https://github.com/mingyuan-zhang/LMM)][`S-Lab + SenseTime`]

* üëç**Humanoid-Gym(arxiv2024.04)** Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer [[arxiv link](https://arxiv.org/abs/2404.05695)][[project link](https://sites.google.com/view/humanoid-gym/)][[code|official](https://github.com/roboterax/humanoid-gym)][`Shanghai Qi Zhi + Robot Era + THU`][The implementation of `Humanoid-Gym` relies on resources from [`legged_gym`](https://github.com/leggedrobotics/legged_gym) and [`rsl_rl`](https://github.com/leggedrobotics/rsl_rl) projects][This codebase is verified by `RobotEra's XBot-S (1.2 meter tall humanoid robot)` and `XBot-L (1.65 meter tall humanoid robot)` in real-world environment with `zero-shot sim-to-real transfer`.]

* **I-CTRL(arxiv2024.05)** I-CTRL: Imitation to Control Humanoid Robots Through Constrained Reinforcement Learning [[arxiv link](https://arxiv.org/abs/2405.08726)][`Technische Universitat Wien (TU Wien), Vienna, Austria`]

* **HumanPlus(arxiv2024.06)** HumanPlus: Humanoid Shadowing and Imitation from Humans [[arxiv link](https://arxiv.org/abs/2406.10454)][[project link](https://humanoid-ai.github.io/)][[code|official](https://github.com/MarkFzp/humanplus)][`Stanford University`]

* **Jumping CoD(arxiv2024.09)** Agile Continuous Jumping in Discontinuous Terrains [[arxiv link](https://arxiv.org/abs/2409.10923)][[project link](https://yxyang.github.io/jumping_cod/)][[code|official](https://github.com/yxyang/jumping_cod)][`University of Washington + Google Deepmind + Carnegie Mellon University`][using `Unitree Go1 robot`]

* **GVHMR(SIGGRAPH2024)(arxiv2024.09)** World-Grounded Human Motion Recovery via Gravity-View Coordinates [[arxiv link](https://arxiv.org/abs/2409.06662)][[project link](https://zju3dv.github.io/gvhmr/)][[code|official](https://github.com/zju3dv/GVHMR)][[huggingface demo](https://huggingface.co/spaces/LittleFrog/GVHMR)][`Zhejiang University + The University of Hong Kong + Deep Glint + Shenzhen University`]
