#  List of public algorithms and datasets

## 1) Pubilc Datasets and Challenges

### â­**For Head Pose Estimation**
* [BIWI RGBD-ID Dataset](http://robotics.dei.unipd.it/reid/index.php): The BIWI RGBD-ID Dataset is a RGB-D dataset of people targeted to long-term people re-identification from RGB-D cameras. It contains 50 training and 56 testing sequences of 50 different people.
* [300W-LP & AFLW2000-3D](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3ddfa/main.htm): 300W-LP has the synthesized large-pose face images from 300W. AFLW2000-3D is the fitted 3D faces of the first 2000 AFLW samples, which can be used for 3D face alignment evaluation.
* [CMU Panoptic Studio Dataset](http://domedb.perception.cs.cmu.edu/index.html): Currently, 480 VGA videos, 31 HD videos, 3D body pose, and calibration data are available. PointCloud DB from 10 Kinects (with corresponding 41 RGB videos) is also available (6+ hours of data). Please refer the official website for details. Dataset paper link [Panoptic studio: A massively multiview system for social interaction capture](https://arxiv.org/pdf/1612.03153.pdf).

### â­**For Head Detection**
* [HollywoodHead dataset](https://www.di.ens.fr/willow/research/headdetection/): HolleywoodHeads dataset is a head detection datset. HollywoodHeads dataset contains 369846 human heads annotated in 224740 video frames from 21 Hollywood movies.
* [Brainwash dataset](https://exhibits.stanford.edu/data/catalog/sx925dc9385): Brainwash dataset is related for face detection. Brainwash dataset contains 11917 images with 91146 labeled people.
* [SCUT-HEAD-Dataset-Release](https://github.com/HCIILAB/SCUT-HEAD-Dataset-Release): SCUT-HEAD is a large-scale head detection dataset, including 4405 images labeld with 111251 heads. The dataset consists of two parts. PartA includes 2000 images sampled from monitor videos of classrooms in an university with 67321 heads annotated. PartB includes 2405 images crawled from Internet with 43930 heads annotated.

### â­**For Head Detection or Crowd Counting**
* [ShanghaiTech dataset](https://github.com/desenzhou/ShanghaiTechDataset): Dataset appeared in Single Image Crowd Counting via Multi Column Convolutional Neural Network(MCNN) in CVPR2016. ã€æƒ…å†µä»‹ç»ã€‘ï¼šåŒ…å«æ ‡æ³¨å›¾ç‰‡ 1198 å¼ ï¼Œå…± 330165 äººï¼Œåˆ†ä¸º A å’Œ B ä¸¤ä¸ªéƒ¨åˆ†ï¼ŒA åŒ…å« 482 å¼ å›¾ç‰‡ï¼Œå‡ä¸ºç½‘ç»œä¸‹è½½çš„å«é«˜åº¦æ‹¥æŒ¤äººç¾¤çš„åœºæ™¯å›¾ç‰‡ï¼Œäººç¾¤æ•°é‡ä» 33 åˆ° 3139 ä¸ªä¸ç­‰ï¼Œè®­ç»ƒé›†åŒ…å« 300 å¼ å›¾ç‰‡å’Œæµ‹è¯•é›†åŒ…å« 182 å¼ å›¾ç‰‡ã€‚B åŒ…å« 716 å¼ å›¾ç‰‡ï¼Œè¿™äº›å›¾ç‰‡çš„äººæµåœºæ™¯ç›¸å¯¹ç¨€ç–ï¼Œæ‹æ‘„äºè¡—é“çš„å›ºå®šæ‘„åƒå¤´ï¼Œç¾¤ä½“æ•°é‡ä» 12 åˆ° 578 ä¸ç­‰ã€‚è®­ç»ƒé›†åŒ…å« 400 å¼ å›¾åƒï¼Œæµ‹è¯•é›†åŒ…å« 316 å¼ å›¾åƒã€‚
* [UCF-QNRF - A Large Crowd Counting Data Set](https://www.crcv.ucf.edu/data/ucf-qnrf/): It contains 1535 images which are divided into train and test sets of 1201 and 334 images respectively. Paper is published in ECCV2018. ã€æƒ…å†µä»‹ç»ã€‘ï¼šè¿™æ˜¯æœ€æ–°å‘å¸ƒçš„æœ€å¤§äººç¾¤æ•°æ®é›†ã€‚å®ƒåŒ…å« 1535 å¼ æ¥è‡ª Flickrã€ç½‘ç»œæœç´¢å’Œ Hajj ç‰‡æ®µçš„å¯†é›†äººç¾¤å›¾åƒã€‚æ•°æ®é›†åŒ…å«å¹¿æ³›çš„åœºæ™¯ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è§†è§’ã€ç…§æ˜å˜åŒ–å’Œå¯†åº¦å¤šæ ·æ€§ï¼Œè®¡æ•°èŒƒå›´ä» 49 åˆ° 12865 ä¸ç­‰ï¼Œè¿™ä½¿è¯¥æ•°æ®åº“æ›´åŠ å›°éš¾å’Œç°å®ã€‚æ­¤å¤–ï¼Œå›¾åƒåˆ†è¾¨ç‡ä¹Ÿå¾ˆå¤§ï¼Œå› æ­¤å¯¼è‡´å¤´éƒ¨å°ºå¯¸å‡ºç°å¤§å¹…å˜åŒ–ã€‚
* [UCSD Pedestrian Dataset](http://visal.cs.cityu.edu.hk/downloads/): Video of people on pedestrian walkways at UCSD, and the corresponding motion segmentations. Currently two scenes are available. ã€æƒ…å†µä»‹ç»ã€‘ï¼šç”± 2000 å¸§ç›‘æ§æ‘„åƒæœºæ‹æ‘„çš„ç…§ç‰‡ç»„æˆï¼Œå°ºå¯¸ä¸º 238Ã—158ã€‚è¿™ä¸ªæ•°æ®é›†çš„å¯†åº¦ç›¸å¯¹è¾ƒä½ï¼Œæ¯å¹…å›¾åƒ 11 åˆ° 46 äººä¸ç­‰ï¼Œå¹³å‡çº¦ 25 äººã€‚åœ¨æ‰€æœ‰å¸§ä¸­ï¼Œå¸§ 601 åˆ° 1400 ä¸ºè®­ç»ƒé›†ï¼Œå…¶ä½™å¸§ä¸ºæµ‹è¯•é›†ã€‚
* [Megvii CrowdHuman](https://www.crowdhuman.org/): CrowdHuman is a benchmark dataset to better evaluate detectors in crowd scenarios. The CrowdHuman dataset is large, rich-annotated and contains high diversity. CrowdHuman contains 15000, 4370 and 5000 images for training, validation, and testing, respectively. There are a total of 470K human instances from train and validation subsets and 23 persons per image, with various kinds of occlusions in the dataset. Each human instance is annotated with a head bounding-box, human visible-region bounding-box and human full-body bounding-box. We hope our dataset will serve as a solid baseline and help promote future research in human detection tasks.


## 2) Pioneers and Experts

[ğŸ‘Jian Sun](http://www.jiansun.org/) [ğŸ‘Gang YU](http://www.skicyyu.org/)



## 3) Related Materials (Papers, Sources Code, Blogs, Videos and Applications)

### â–¶ Beautify Face

#### Materials

* [(github) BeautifyFaceDemo](https://github.com/Guikunzhi/BeautifyFaceDemo)
* [(CSDN blogs) å›¾åƒæ»¤é•œè‰ºæœ¯---æ¢è„¸ç®—æ³•èµ„æºæ”¶é›†](https://blog.csdn.net/scythe666/article/details/81021041)

#### Papers



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**


### â–¶ Face Alignment

#### Materials

* [(jianshu) äººè„¸å…³é”®ç‚¹å¯¹é½](https://www.jianshu.com/p/e4b9317a817f)
* Procrustes Analysis [[CSDN blog](https://blog.csdn.net/u011808673/article/details/80733686)][[wikipedia](https://en.wikipedia.org/wiki/Procrustes_analysis)][[scipy.spatial.procrustes](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.procrustes.html)][[github](https://github.com/Ahmer-444/Action-Recognition-ProcrustesAnalysis)]
* (website) Greek Mythology æµ™æ±Ÿå¤§å­¦æ•°å­¦ç§‘å­¦å­¦é™¢å¸Œè…Šç¥è¯æµ™æ±Ÿå¤§å­¦æ•°å­¦ç§‘å­¦å­¦é™¢.ppt [[Procrustes Analysis and its application in computer graphaics](https://max.book118.com/html/2017/0307/94565569.shtm)]
* [(github) ASM-for-human-face-feature-points-matching](https://github.com/JiangtianPan/ASM-for-human-face-feature-points-matching)
* [(github) align_dataset_mtcnn](https://github.com/davidsandberg/facenet/blob/master/src/align/align_dataset_mtcnn.py)
* [(Website) Face Alignment Across Large Poses: A 3D Solution (official website)](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3ddfa/main.htm)

#### Papers

* **3000FPS(CVPR2014)** Face Alignment at 3000 FPS via Regressing Local Binary Features [[paper link](http://www.cse.psu.edu/~rtc12/CSE586/papers/regr_cvpr14_facealignment.pdf)][[Codes|opencv(offical)](https://github.com/freesouls/face-alignment-at-3000fps)][[Codes|liblinear(unoffical)](https://github.com/jwyang/face-alignment)][[CSDN blog](https://blog.csdn.net/lzb863/article/details/49890369)]

* **3DDFA(CVPR2016)** Face Alignment Across Large Poses: A 3D Solution [[paper link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7780392)][[project link](http://www.cbsr.ia.ac.cn/users/xiangyuzhu/projects/3DDFA/main.htm)]

* **face-alignment(ICCV2017)** How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks) [[paper link](https://www.adrianbulat.com/downloads/FaceAlignment/FaceAlignment.pdf)][[Adrian Bulat](https://www.adrianbulat.com/)][[Codes|PyTorch(offical)](https://github.com/1adrianb/face-alignment)][[CSDN blogs](https://www.cnblogs.com/molakejin/p/8027573.html)]

* **PRNet(ECCV2018)** Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network [[arxiv link](https://arxiv.org/abs/1803.07835)][[Codes|TensorFlow(offical)](https://github.com/YadiraF/PRNet)]



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**


### â–¶ Face Detection

#### Materials

* [(github) A-Light-and-Fast-Face-Detector-for-Edge-Devices](https://github.com/YonghaoHe/A-Light-and-Fast-Face-Detector-for-Edge-Devices)
* [(website) FDDB: Face Detection Data Set and Benchmark Home](http://vis-www.cs.umass.edu/fddb/)
* [(CSDN blogs) äººè„¸æ£€æµ‹ï¼ˆåå…«ï¼‰--TinyFace(S3FD,SSH,HR,RSA,Face R-CNN,PyramidBox)](https://blog.csdn.net/App_12062011/article/details/80534351)
* [(github) e2e-joint-face-detection-and-alignment](https://github.com/KaleidoZhouYN/e2e-joint-face-detection-and-alignment)
* [(github) libfacedetection in PyTorch](https://github.com/ShiqiYu/libfacedetection/)
* [(github) 1MB lightweight face detection model (1MBè½»é‡çº§äººè„¸æ£€æµ‹æ¨¡å‹)](https://github.com/Linzaer/Ultra-Light-Fast-Generic-Face-Detector-1MB)
* [(blog) LFFD å†å‡çº§ï¼æ–°å¢è¡Œäººå’Œäººå¤´æ£€æµ‹æ¨¡å‹ï¼ŒåŠä¼˜åŒ–çš„C++å®ç°](https://www.zhuanzhi.ai/document/d36c78507cc5d09dcac3fb7241344f3b)

#### Papers

* **MTCNN(SPL2016)** Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks [[paper link](https://kpzhang93.github.io/MTCNN_face_detection_alignment/paper/spl.pdf)][[project link](https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html)][[Codes|Caffe&Matlab(offical)](https://github.com/kpzhang93/MTCNN_face_detection_alignment)][[Codes|MXNet(unoffical)](https://github.com/YYuanAnyVision/mxnet_mtcnn_face_detection)][[Codes|Tensorflow(unoffical)](https://github.com/AITTSMD/MTCNN-Tensorflow)][[CSDN blog](https://blog.csdn.net/qq_36782182/article/details/83624357)]

* **TinyFace(CVPR2017)** Finding Tiny Faces [[arxiv link](https://arxiv.org/abs/1612.04402)][[preject link](https://www.cs.cmu.edu/~peiyunh/tiny/)][[Codes|MATLAB(offical)](https://github.com/peiyunh/tiny)][[Codes|PyTorch(unoffical)](https://github.com/varunagrawal/tiny-faces-pytorch)][[Codes|MXNet(unoffical)](https://github.com/chinakook/hr101_mxnet)][[Codes|Tensorflow(unoffical)](https://github.com/cydonia999/Tiny_Faces_in_Tensorflow)]

* **FaceBoxes(IJCB2017)** FaceBoxes: A CPU Real-time Face Detector with High Accuracy [[arxiv link](https://arxiv.org/abs/1708.05234)][[Codes|Caffe(offical)](https://github.com/sfzhang15/FaceBoxes)][[Codes|PyTorch(unoffical)](https://github.com/zisianw/FaceBoxes.PyTorch)]

* **SSH(ICCV2017)** SSH: Single Stage Headless Face Detector [[arxiv link](https://arxiv.org/abs/1708.03979)][[Codes|Caffe(offical)](https://github.com/mahyarnajibi/SSH)][[Codes|MXNet(unoffical SSH with Alignment)](https://github.com/ElegantGod/SSHA)][[Codes|(unoffical enhanced-ssh-mxnet)](https://github.com/deepinx/enhanced-ssh-mxnet)]

* **S3FD(ICCV2017)** SÂ³FD: Single Shot Scale-invariant Face Detector [[arxiv link](https://arxiv.org/abs/1708.05237)][[Codes|Caffe(offical)](https://github.com/sfzhang15/SFD)]

* **RSA(ICCV2017)** Recurrent Scale Approximation (RSA) for Object Detection [[arxiv link](https://arxiv.org/abs/1707.09531)][[Codes|Caffe(offical)](https://github.com/liuyuisanai/RSA-for-object-detection)]

* **DSFD(CVPR2019)** DSFD: Dual Shot Face Detector [[arxiv link](https://arxiv.org/abs/1810.10220)][[Codes|PyTorch(offical)](https://github.com/yxlijun/DSFD.pytorch)][[CSDN blog](https://blog.csdn.net/wwwhp/article/details/83757286)]

* **LFFD(arxiv2019)** LFFD: A Light and Fast Face Detector for Edge Devices [[arxiv link](https://arxiv.org/abs/1904.10633)][[Codes|PyTorch, offical V1](https://github.com/YonghaoHe/LFFD-A-Light-and-Fast-Face-Detector-for-Edge-Devices)][[Codes|PyTorch, offical V2](https://github.com/YonghaoHe/LFD-A-Light-and-Fast-Detector)]



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

### â–¶ Face Recognition

#### Materials

* [(website) EyeKey çœ¼ç¥ç§‘æŠ€](http://www.eyekey.com/)
* [(CSDN blogs) äººè„¸æ¯”å¯¹ï¼ˆ1:Nï¼‰](https://blog.csdn.net/intflojx/article/details/81278330)
* [(github) Face Recognition (dlib with deep learning reaching 99.38% acc in LFW)](https://github.com/ageitgey/face_recognition)
* [(website) face_recognition package](https://face-recognition.readthedocs.io/en/latest/face_recognition.html)

###3 Papers

* **ArcFace/InsightFace(CVPR2019)** ArcFace: Additive Angular Margin Loss for Deep Face Recognition [[arxiv link](https://arxiv.org/abs/1801.07698)][[Codes|MXNet(offical insightface)](https://github.com/deepinsight/insightface)][[Codes|MXNet(offical ArcFace)](https://github.com/deepinsight/insightface/tree/master/recognition/ArcFace)][[CSDN blog](https://blog.csdn.net/fire_light_/article/details/79602705)]

* **SubCenter-ArcFace(ECCV2020)** Sub-center ArcFace: Boosting Face Recognition by Large-scale Noisy Web Faces [[paper link](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123560715.pdf)][[Codes|MXNet(offical SubCenter-ArcFace)](https://github.com/deepinsight/insightface/tree/master/recognition/SubCenter-ArcFace)][[CSDN blogs](https://blog.csdn.net/XBB102910/article/details/109400771)]


**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

### â–¶ Face Reconstruction (3D)

#### Materials

#### Papers

* **VRN(ICCV2017)** Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression [[arxiv link](https://arxiv.org/abs/1703.07834)][[project link](http://aaronsplace.co.uk/papers/jackson2017recon/)][[online website](https://cvl-demos.cs.nott.ac.uk/vrn/)][[Codes|Torch7(offical)](https://github.com/AaronJackson/vrn)]

* **PRNet(ECCV2018)** Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network [[arxiv link](https://arxiv.org/abs/1803.07835)][[Codes|TensorFlow(offical)](https://github.com/YadiraF/PRNet)]



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

### â–¶ Head Detector

### Materials

* [(zhihu) ä¸€æ–‡è¯»æ‡‚YOLO V5 ä¸ YOLO V4](https://zhuanlan.zhihu.com/p/161083602?d=1605663864267)
* [(zhihu) å¦‚ä½•è¯„ä»·YOLOv5ï¼Ÿ](https://www.zhihu.com/question/399884529)
* [(csdn blog) YOLO/V1ã€V2ã€V3ç›®æ ‡æ£€æµ‹ç³»åˆ—ä»‹ç»](https://blog.csdn.net/qq26983255/article/details/82119232)
* [(csdn blog) ç¿æ™ºçš„ç›®æ ‡æ£€æµ‹26â€”â€”Pytorchæ­å»ºyolo3ç›®æ ‡æ£€æµ‹å¹³å°](https://blog.csdn.net/weixin_44791964/article/details/105310627)
* [(csdn blog) ç¿æ™ºçš„ç›®æ ‡æ£€æµ‹30â€”â€”Pytorchæ­å»ºYoloV4ç›®æ ‡æ£€æµ‹å¹³å°](https://blog.csdn.net/weixin_44791964/article/details/106214657/)

### Papers

* **ReInspect, Lhungarian(CVPR2016)** End-To-End People Detection in Crowded Scenes [[arxiv link](https://arxiv.org/abs/1506.04878)]

* **DA-RCNN(CVPR2018)** Double Anchor R-CNN for Human Detection in a Crowd [[arxiv link](https://arxiv.org/abs/1909.09998)][[CSDN blog1](https://blog.csdn.net/Suan2014/article/details/103987896)][[CSDN blog2](https://blog.csdn.net/Megvii_tech/article/details/103485685)]

* **FCHD(arxiv2018,ICIP2019)** FCHD: Fast and accurate head detection in crowded scenes [[arxiv link](https://arxiv.org/abs/1809.08766)][[Codes|PyTorch(official)](https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector)][[CSDN blog](https://blog.csdn.net/javastart/article/details/82865858)]

* **LSC-CNN(TPAMI2020)** Locate, Size and Count: Accurately Resolving People in Dense Crowds via Detection [[arxiv link](https://arxiv.org/abs/1906.07538)][[Codes|Pytorch(official)](https://github.com/val-iisc/lsc-cnn)]
 
* **YOLOv5** YOLOv5 is from the family of object detection architectures YOLO and has no paper [[YOLOv5 Docs](https://docs.ultralytics.com/)][[Code|PyTorch(official)](https://github.com/ultralytics/yolov5)]



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

### â–¶ Head Pose Estimation

#### Materials

* [(tutorial & blog) Head Pose Estimation using OpenCV and Dlib](https://www.learnopencv.com/head-pose-estimation-using-opencv-and-dlib/)
* [(blogs) åŸºäºDlibå’ŒOpenCVçš„äººè„¸å§¿æ€ä¼°è®¡(HeadPoseEstimation))](https://blog.csdn.net/u013512448/article/details/77804161)
* [(blogs) ä½¿ç”¨opencvå’Œdlibè¿›è¡Œäººè„¸å§¿æ€ä¼°è®¡(python)](https://blog.csdn.net/yuanlulu/article/details/82763170)
* [(cnblogs) paper 154ï¼šå§¿æ€ä¼°è®¡ï¼ˆHand Pose Estimationï¼‰ç›¸å…³æ€»ç»“](https://www.cnblogs.com/molakejin/p/8021574.html)
* [(blogs) solvepnpä¸‰ç»´ä½å§¿ä¼°ç®— | PnP å•ç›®ç›¸æœºä½å§¿ä¼°è®¡ï¼ˆä¸€ã€äºŒã€ä¸‰ï¼‰](https://blog.csdn.net/cocoaqin/article/details/77485436)
* [(github) OpenFace 2.2.0: a facial behavior analysis toolkit](https://github.com/TadasBaltrusaitis/OpenFace)
* [(github) Deepgaze contains useful packages including Head Pose Estimation](https://github.com/mpatacchiola/deepgaze)
* [(github) [Suggestion] Annotate rigid objects in 2D image with standard 3D cube](https://github.com/openvinotoolkit/cvat/issues/3387)

#### Papers(Journal)

* **Survey(TPAMI2019)** Head Pose Estimation in Computer Vision: A Survey [[paper link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4497208)][[CSDN blog](https://blog.csdn.net/weixin_41703033/article/details/83215043)]

* **Quatnet(Multimedia2019)** Quatnet: Quaternion-based head pose estimation with multiregression loss [[paper link](https://ieeexplore.ieee.org/abstract/document/8444061)]

* **(IVC2020)** Improving head pose estimation using two-stage ensembles with top-k regression [[paper link](https://www.sciencedirect.com/sdfe/reader/pii/S0262885619304202/pdf)]

* **(TPAMI2020)** Multi-Task Head Pose Estimation in-the-Wild [[paper link](https://bobetocalo.github.io/pdf/paper_pami20.pdf)][[codes|Tensorflow / C++](https://github.com/bobetocalo/bobetocalo_pami20)]

#### Papers(Conference)

* â­**HopeNet(CVPRW2018)** Fine-Grained Head Pose Estimation Without Keypoints [[arxiv link](https://arxiv.org/abs/1710.00925)][[Codes|PyTorch(official)](https://github.com/natanielruiz/deep-head-pose)][[CSDN blog](https://blog.csdn.net/qq_42189368/article/details/84849638)]

* â­**FSA-Net(CVPR2019)** FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation from a Single Image [[paper link](https://github.com/shamangary/FSA-Net/blob/master/0191.pdf)][[Codes|Keras&Tensorflow(official)](https://github.com/shamangary/FSA-Net)]

* â­**WHENet(BMVC2020)** WHENet: Real-time Fine-Grained Estimation for Wide Range Head Pose [[arxiv link](https://arxiv.org/abs/2005.10353)][[Codes|Kears&tensorflow(official)](https://github.com/Ascend-Research/HeadPoseEstimation-WHENet)]

* **RAFA-Net(ACCV2020)** Rotation Axis Focused Attention Network (RAFA-Net) for Estimating Head Pose [[paper link](https://openaccess.thecvf.com/content/ACCV2020/html/Behera_Rotation_Axis_Focused_Attention_Network_RAFA-Net_for_Estimating_Head_Pose_ACCV_2020_paper.html)][[codes|keras+tensorflow](https://github.com/ArdhenduBehera/RAFA-Net)]

* **FDN(AAAI2020)** FDN: Feature decoupling network for head pose estimation [[paper link](https://ojs.aaai.org/index.php/AAAI/article/view/6974)]

* **EVA-GCN(CVPRW2021)** EVA-GCN: Head Pose Estimation Based on Graph Convolutional Networks [[paper link](http://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Xin_EVA-GCN_Head_Pose_Estimation_Based_on_Graph_Convolutional_Networks_CVPRW_2021_paper.html)][[codes|PyTorch](https://github.com/stoneMo/EVA-GCN)]

* **TriNet(WACV2021)** A Vector-Based Representation to Enhance Head Pose Estimation
 [[paper link](http://openaccess.thecvf.com/content/WACV2021/html/Chu_A_Vector-Based_Representation_to_Enhance_Head_Pose_Estimation_WACV_2021_paper.html)][[codes|Tensorflow+Keras](https://github.com/anArkitek/TriNet_WACV2021)]

* **img2pose(CVPR2021)** img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation [[paper link](https://openaccess.thecvf.com/content/CVPR2021/html/Albiero_img2pose_Face_Alignment_and_Detection_via_6DoF_Face_Pose_Estimation_CVPR_2021_paper.html)][[codes|PyTorch](http://github.com/vitoralbiero/img2pose)]

* **OsGG-Net(ACMMM2021)** OsGG-Net: One-step Graph Generation Network for Unbiased Head Pose Estimation [[paper link](https://dl.acm.org/doi/abs/10.1145/3474085.3475417)][[codes|PyTorch](https://github.com/stoneMo/OsGG-Net)]

* **(KSE2021)** Simultaneous face detection and 360 degree head pose estimation [[paper link](https://ieeexplore.ieee.org/abstract/document/9648838)]

* **LwPosr(WACV2022)** LwPosr: Lightweight Efficient Fine Grained Head Pose Estimation [[paper link](https://openaccess.thecvf.com/content/WACV2022/html/Dhingra_LwPosr_Lightweight_Efficient_Fine_Grained_Head_Pose_Estimation_WACV_2022_paper.html)]

* **HHP-Net(WACV2022)** HHP-Net: A Light Heteroscedastic Neural Network for Head Pose Estimation With Uncertainty [[paper link](https://openaccess.thecvf.com/content/WACV2022/html/Cantarini_HHP-Net_A_Light_Heteroscedastic_Neural_Network_for_Head_Pose_Estimation_WACV_2022_paper.html)][[codes|TensorFlow](https://github.com/cantarinigiorgio/HHP-Net)]


