# Here are collections about other CV topics

**Contents Hyperlinks**

* [⭐3D Camera](#3d-camera)
* [⭐6D Object Pose Estimation](#6d-object-pose-estimation)
* [⭐Deep Neural Networks](#deep-neural-networks)
* [⭐Eye Gaze](#eye-gaze)
* [⭐Generative Adversarial Network](#generative-adversarial-network)
* [⭐Image Mosaic](#image-mosaic)
* [⭐Image Restoration](#image-restoration)
* [⭐Lane Detection](#lane-detection)
* [⭐Pedestrian Localization](#pedestrian-localization)
* [⭐Person ReID](#person-reid)
* [⭐Semantic Segmentation](#semantic-segmentation)
* [⭐SLAM (Simultaneous Localization and Mapping)](#slam-simultaneous-localization-and-mapping)
* [⭐Sound Source Localization](#sound-source-localization)
* [⭐Text Detection](#text-detection)
* [⭐Traffic Violation Detection](#traffic-violation-detection)


**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐3D Camera

### Materials

* [(website) A Comprehensive List of 3D Sensors Commonly Leveraged in ROS Development](https://rosindustrial.org/3d-camera-survey)
* [(CSDN) 【深度相机系列六】深度相机哪家强？附详细参数对比清单](https://blog.csdn.net/electech6/article/details/78907463)

### Papers


**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐6D Object Pose Estimation

### Materials

* [(CSDN blogs) 6D姿态估计算法汇总（上）](https://blog.csdn.net/qq_29462849/article/details/103740960)
* [(CSDN blogs) 6D姿态估计算法汇总（下）](https://blog.csdn.net/qq_29462849/article/details/103741059)
* [(zhihu) VR设备常说的3DOF和6DOF到底是什么？](https://zhuanlan.zhihu.com/p/114650000)
* [(github) Awesome work on object 6 DoF pose estimation](https://github.com/ZhongqunZHANG/awesome-6d-object)

### Papers

* **DPOD(ICCV2019)** DPOD: 6D Pose Object Detector and Refiner [[paper link](https://openaccess.thecvf.com/content_ICCV_2019/html/Zakharov_DPOD_6D_Pose_Object_Detector_and_Refiner_ICCV_2019_paper.html)][[codes|PyTorch](https://github.com/zakharos/DPOD)]

* **(CVPR2020)** Single-Stage 6D Object Pose Estimation [[paper link](https://openaccess.thecvf.com/content_CVPR_2020/html/Hu_Single-Stage_6D_Object_Pose_Estimation_CVPR_2020_paper.html)]

* **SGPA(ICCV2021)** SGPA: Structure-Guided Prior Adaptation for Category-Level 6D Object Pose Estimation [[paper link](https://openaccess.thecvf.com/content/ICCV2021/html/Chen_SGPA_Structure-Guided_Prior_Adaptation_for_Category-Level_6D_Object_Pose_Estimation_ICCV_2021_paper.html)][[codes|PyTorch](https://github.com/leo94-hk/SGPA)]

* **Objectron(CVPR2021)** Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild With Pose Annotations [[paper link](https://openaccess.thecvf.com/content/CVPR2021/html/Ahmadyan_Objectron_A_Large_Scale_Dataset_of_Object-Centric_Videos_in_the_CVPR_2021_paper.html)][[codes|PyTorch+TensorFlow](https://github.com/google-research-datasets/Objectron)]

* **SAR-Net(CVPR2022)** SAR-Net: Shape Alignment and Recovery Network for Category-level 6D Object Pose and Size Estimation [[paper link]()][[project link](https://hetolin.github.io/SAR-Net/)][[codes|official](https://github.com/hetolin/SAR-Net)]

* **OVE6D-pose(CVPR2022)** OVE6D: Object Viewpoint Encoding for Depth-based 6D Object Pose Estimation [[paper link](https://arxiv.org/pdf/2203.01072.pdf)][[project link](https://dingdingcai.github.io/ove6d-pose/)][[codes|official](https://github.com/dingdingcai/OVE6D-pose)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Eye Gaze

### Materials


### Papers

* **ETH-XGaze(ECCV2020)** ETH-XGaze: A Large Scale Dataset for Gaze Estimation under Extreme Head Pose and Gaze Variation [[arxiv link](https://arxiv.org/abs/2007.15837)][[project link](https://ait.ethz.ch/projects/2020/ETH-XGaze/)][[Codes|PyTorch(official)](https://github.com/xucong-zhang/ETH-XGaze)]

* **EVE(ECCV2020)** Towards End-to-end Video-based Eye-tracking [[arxiv link](https://arxiv.org/abs/2007.13120)][[project link](https://ait.ethz.ch/projects/2020/EVE/)][[Codes|PyTorch(official)](https://github.com/swook/EVE)]


**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Generative Adversarial Network

### Materials

* [(blog) Test and Train CycleGAN](https://colab.research.google.com/github/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/CycleGAN.ipynb#scrollTo=OzSKIPUByfiN)
* [(CSDNblog) CycleGAN论文的阅读与翻译，无监督风格迁移](https://zhuanlan.zhihu.com/p/45394148)
* [(CSDNblog) 生成对抗网络(四)CycleGAN讲解](https://blog.csdn.net/qq_40520596/article/details/104714762)

### Papers

* **CycleGAN(ICCV2017)** Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks [[arxiv link](https://arxiv.org/pdf/1703.10593.pdf)][[project link](https://junyanz.github.io/CycleGAN/)][[Codes|PyTorch(official)](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)]

* **CUT(ECCV2020)** Contrastive Learning for Unpaired Image-to-Image Translation [[arxiv link](https://arxiv.org/abs/2007.15651)][[project link](http://taesung.me/ContrastiveUnpairedTranslation/)][[Codes|PyTorch(official)](https://github.com/taesungp/contrastive-unpaired-translation)]



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Deep Neural Networks

### Frameworks

* **PyTorch** [Home Page](https://pytorch.org/), [Offical Documentation](https://pytorch.org/docs/stable/index.html)
* **TensorFlow** [Home Page](https://tensorflow.google.cn/), [Offical Documentation](https://tensorflow.google.cn/versions/r1.15/api_docs/python/tf)

### Materials

* [Efficient Processing of Deep Neural Networks: A Tutorial and Survey](https://arxiv.org/pdf/1703.09039.pdf)
* [(CSDN blog) 五大经典卷积神经网络介绍：LeNet / AlexNet / GoogLeNet / VGGNet/ ResNet](https://blog.csdn.net/fendouaini/article/details/79807830)
* [(cnblogs) Deep Learning回顾#之LeNet、AlexNet、GoogLeNet、VGG、ResNet](https://www.cnblogs.com/52machinelearning/p/5821591.html)
* [(github) HRNet: HRNet-Applications-Collection](https://github.com/HRNet/HRNet-Applications-Collection)

### Papers



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Image Mosaic


### Materials

* [(zhihu) 基于图像的三维建模——特征点检测与匹配](https://zhuanlan.zhihu.com/p/128937547)
* [(website) 图像拼接算法的综述 - A survey on image mosaicing techniques](http://s1nh.org/post/A-survey-on-image-mosaicing-techniques/)
* [(cnblogs) OpenCV探索之路（二十四）图像拼接和图像融合技术](https://www.cnblogs.com/skyfsm/p/7411961.html)
* [(zhihu - YaqiLYU) 图像拼接现在还有研究的价值吗？有哪些可以研究的点？现在技术发展如何？](https://www.zhihu.com/question/34535199/answer/135169187)
* [(zhihu - YaqiLYU) 目前最成熟的全景视频拼接技术是怎样的？](https://www.zhihu.com/question/34573969/answer/136464893)
* [(opencv docs) Feature Detection and Description](https://docs.opencv.org/master/db/d27/tutorial_py_table_of_contents_feature2d.html)
* [(github) [Real-Time Image Stitching] CS205 Computing Foundations for Computational Science Final Project(C++)](https://github.com/ziqiguo/CS205-ImageStitching)
* [(github) [Image and Video Stitching] Conducts image stitching upon an input video to generate a panorama in 3D(Python)](https://github.com/WillBrennan/ImageStitching)
* [(github) Multiple Image stitching in Python](https://github.com/kushalvyas/Python-Multiple-Image-Stitching)


### Papers

* **NISwGSP(ECCV2016)** Natural Image Stitching with the Global Similarity Prior [[paper link](https://link.springer.com/chapter/10.1007%2F978-3-319-46454-1_12)][[Codes|offical C++ & Matlab](https://github.com/nothinglo/NISwGSP)]

* **VFSMS(CMS2019)** A Fast Algorithm for Material Image Sequential Stitching [[paper link](http://www.sciencedirect.com/science/article/pii/S0927025618307158)][[software](https://www.mgedata.cn/app_entrance/microscope)][[Codes|offical python & C++](https://github.com/Keep-Passion/ImageStitch)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Image Restoration

Image restoration includes **image in-painting**, **pixel interpolation**, **image deblurring**, and **image denoising**.
 
### Materials

* [(github) CNN-For-End-to-End-Deblurring (Keras)](https://github.com/axium/CNN-For-End-to-End-Deblurring--Keras)

### Papers

* **DnCNN(TIP2017)** Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising [[paper link](http://www4.comp.polyu.edu.hk/~cslzhang/paper/DnCNN.pdf)][[Codes|MATLAB(offical)](https://github.com/cszn/DnCNN)]

* **MemNet(ICCV2017)** MemNet: A Persistent Memory Network for Image Restoration [[paper link](http://cvlab.cse.msu.edu/pdfs/Image_Restoration%20using_Persistent_Memory_Network.pdf)][[Codes|Matlab(offical)](https://github.com/tyshiwo/MemNet)]

* **pix2pix(CVPR2017)** Image-to-Image Translation with Conditional Adversarial Nets [[arxiv link](https://arxiv.org/abs/1611.07004)][[project link](https://phillipi.github.io/pix2pix/)][[Codes|Torch(offical)](https://github.com/phillipi/pix2pix)][[Codes|PyTorch(offical)](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)]

* **DeepDeblur(CVPR2017)** [[paper link](https://openaccess.thecvf.com/content_cvpr_2017/papers/Nah_Deep_Multi-Scale_Convolutional_CVPR_2017_paper.pdf)][[Codes|Torch(offical)](https://github.com/SeungjunNah/DeepDeblur_release)][[Codes|PyTorch(offical)](https://github.com/SeungjunNah/DeepDeblur-PyTorch)]

* **ImageDeblurring(ICCV2017)** Deep Generative Filter for motion deblurring [[arxiv link](https://arxiv.org/abs/1709.03481)][[Codes|Keras&Tensorflow(offical)](https://github.com/leftthomas/ImageDeblurring)]

* **DeblurGAN(CVPR2017)** DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks [[arxiv link](https://arxiv.org/pdf/1711.07064.pdf)][[Codes|PyTorch(offical)](https://github.com/KupynOrest/DeblurGAN)]

* **SRN-Deblur(CVPR2018)** Scale-recurrent Network for Deep Image Deblurring [[paper link](http://www.xtao.website/projects/srndeblur/srndeblur_cvpr18.pdf)][[Codes|Tensorflow(offical)](https://github.com/jiangsutx/SRN-Deblur)]

* **RNN-Deblur(CVPR2018)** Dynamic Scene Deblurring Using Spatially Variant Recurrent Neural Networks [[paper link](https://www.cs.cityu.edu.hk/~rynson/papers/cvpr18c.pdf)][[Codes|Matcaffe(offical)](https://github.com/zhjwustc/cvpr18_rnn_deblur_matcaffe)]

* **Deep-Semantic-Face(CVPR2018)** Deep Semantic Face Deblurring [[paper link](https://research.nvidia.com/sites/default/files/pubs/2018-06_Deep-Semantic-Face//DeepSemanticFaceDeblur_CVPR18.pdf)][[project link](https://research.nvidia.com/publication/2018-06_Deep-Semantic-Face)][[Codes|Matlab(offical)](https://github.com/joanshen0508/Deep-Semantic-Face-Deblurring)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Lane Detection

### Materials

### Datasets

* **CULane** SCNN(AAAI2018) Spatial As Deep: Spatial CNN for Traffic Scene Understanding [[dataset homepage](https://xingangpan.github.io/projects/CULane.html)]

### Papers
 
* **SCNN(AAAI2018)** Spatial As Deep: Spatial CNN for Traffic Scene Understanding [[arxiv link](https://arxiv.org/abs/1712.06080)][[Codes|offical Torch & Matlab](https://github.com/XingangPan/SCNN)]

* **LaneNet(IVS2018)** Towards End-to-End Lane Detection: an Instance Segmentation Approach [[arxiv link](https://arxiv.org/abs/1802.05591)][[project link](https://maybeshewill-cv.github.io/lanenet-lane-detection/)][[Codes|unoffical TF](https://github.com/MaybeShewill-CV/lanenet-lane-detection)]

* **UltraLane(ECCV2020)** Ultra Fast Structure-aware Deep Lane Detection [[arxiv link](https://arxiv.org/abs/2004.11757)][[Codes|offical PyTorch](https://github.com/cfzd/Ultra-Fast-Lane-Detection)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Pedestrian Localization

### Materials


### Papers

* **Monoloco(ICCV2019)** MonoLoco: Monocular 3D Pedestrian Localization and Uncertainty Estimation [[arxiv link](https://arxiv.org/abs/1906.06059)][[Codes|PyTorch(offical)](https://github.com/vita-epfl/monoloco)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Person ReID

### Materials

* [(zhihu) 从零开始行人重识别](https://zhuanlan.zhihu.com/p/50387521)
* [(zhihu) (转)行人重识别(ReID) ——技术实现及应用场景](https://zhuanlan.zhihu.com/p/64362368)
* [(zhihu) 一些想法：关于行人检测与重识别](https://zhuanlan.zhihu.com/p/39282286)
* [(zhihu) 零基础实战行人重识别ReID项目-基于Milvus的以图搜图](https://zhuanlan.zhihu.com/p/141204192)
* [(csdnblog) 行人重识别（Person Re-ID）【一】：常用评测指标](https://blog.csdn.net/qq_38451119/article/details/83000061)
* [(csdnblog) 云从科技：详解跨镜追踪（ReID）技术实现及应用场景](https://edu.csdn.net/course/detail/8426)
* [(tencent cloud) 云从科技资深算法研究员：详解跨镜追踪(ReID)技术实现及难点 | 公开课笔记](https://cloud.tencent.com/developer/article/1160607)

### Datasets

* [Market1501 [Tsinghua University; 32217 images; 1501 persons; 6 cameras]](http://liangzheng.com.cn/Project/project_reid.html)
* [DukeMTMC-ReID [Duke University; 36441 images; 1812 persons; 8 cameras]](https://github.com/sxzrt/DukeMTMC-reID_evaluation#download-dataset)
* [CUHK03 [CUHK University; 13164 images; 1467 persons; 10 cameras]](http://www.ee.cuhk.edu.hk/~xgwang/CUHK_identification.html)

### Papers

* **(TOMM2017)** A Discriminatively Learned CNN Embedding for Person Re-identification [[arxiv link](https://arxiv.org/pdf/1611.05666.pdf)][[Codes|caffe+keras(official)](https://github.com/layumi/2016_person_re-ID)][[CSDN blog](https://blog.csdn.net/weixin_41427758/article/details/80091596)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**


## ⭐Semantic Segmentation

### Materials

* [(CSDN blogs) 语义分割 - Semantic Segmentation Papers](https://blog.csdn.net/langb2014/article/details/82414918)

### Papers

* **FCIS(CVPR2017)** Fully Convolutional Instance-aware Semantic Segmentation [[arxiv link](https://arxiv.org/abs/1611.07709)][[Codes|MXNet(offical based on RFCN)](https://github.com/msracver/FCIS)][[CSDN blog](https://blog.csdn.net/jiongnima/article/details/78961147)]

* **BezierSeg(arxiv2021)** BezierSeg: Parametric Shape Representation for Fast Object Segmentation in Medical Images [[paper link](https://arxiv.org/abs/2108.00760)]

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**


## ⭐SLAM (Simultaneous Localization and Mapping)

### Materials

* [(cnblogs) 视觉SLAM漫谈](https://blog.csdn.net/weixin_41537599/article/details/110819969)

### Papers

**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Sound Source Localization

### Materials

* [(cnblogs) 【论文导读】Learning to Localize Sound Source in Visual Scenes】&soundnet的复现](https://blog.csdn.net/zzc15806/article/details/80772152)
* [(cnblogs) 论文【Learning to Localize Sound Source in Visual Scenes】&soundnet的复现](https://www.cnblogs.com/gaoxiang12/p/3695962.html)

### Papers

* **SoundNet(NIPS2016)** SoundNet: Learning Sound Representations from Unlabeled Video [[arxiv link](https://arxiv.org/pdf/1610.09001.pdf)][[Codes|offical TensorFlow](https://github.com/cvondrick/soundnet)][(CSDN blog)[https://blog.csdn.net/zzc15806/article/details/80669883]]
* 
* **SoundLocation(CVPR2018)** Learning to Localize Sound Source in Visual Scenes [[arxiv link](https://arxiv.org/pdf/1803.03849.pdf)][[Codes|offical PyTorch based on SoundNet](https://github.com/ardasnck/learning_to_localize_sound_source)][[Codes|unoffical PyTorch](https://github.com/liyidi/soundnet_localize_sound_source)]



**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Text Detection

### Materials


### Materials

* **ABCNet(CVPR2020)** ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network [[paper link](https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_ABCNet_Real-Time_Scene_Text_Spotting_With_Adaptive_Bezier-Curve_Network_CVPR_2020_paper.pdf)][[codes|Detectron2 & AdelaiDet Toolbox](https://github.com/aim-uofa/AdelaiDet)]

* **ABCNet_v2(TPAMI2021)** ABCNet v2: Adaptive Bezier-Curve Network for Real-time End-to-end Text Spotting [[paper link](https://ieeexplore.ieee.org/abstract/document/9525302)][[codes|Detectron2 & AdelaiDet Toolbox](https://github.com/aim-uofa/AdelaiDet)]


**-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-|-+-**

## ⭐Traffic Violation Detection

### Materials

* [(github) Traffic-Rule-Violation-Detection-System (Tensorflow + OpenALPR )](https://github.com/ShreyAmbesh/Traffic-Rule-Violation-Detection-System)
* [(github) Traffic-Signal-Violation-Detection-System (Tensorflow based YOLOv3)](https://github.com/anmspro/Traffic-Signal-Violation-Detection-System)
* [(github) Traffic-Rules-Violation-Detection (mobilenet-v1)](https://github.com/rahatzamancse/Traffic-Rules-Violation-Detection)
* [(github) Traffic-Rules-Violation-Detection-System (mobilenet-v1)](https://github.com/sakibreza/Traffic-Rules-Violation-Detection-System)
* [(github) Fully-Automated-red-light-Violation-Detection (Tensorflow based YOLOv3)](https://github.com/AhmadYahya97/Fully-Automated-red-light-Violation-Detection)
* [(github) yolov3-vehicle-detection-paddle](https://github.com/Sharpiless/yolov3-vehicle-detection-paddle) [[CSDN link](https://blog.csdn.net/weixin_45449540/article/details/107345738)]

### Papers



